{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1435b29-7802-4526-8942-4a3c7d611e3e",
   "metadata": {},
   "source": [
    "# Inference with RHODS Model Serving\n",
    "\n",
    "This notebook showcases how to consume an ML model that is deployed with Red Hat OpenShift Data Science (RHODS) Model Serving. It is based on [Ultraface](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB), a lightweight face detection model that was designed for edge computing platforms.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "This notebook requires the following libraries:\n",
    "- numpy\n",
    "- requests\n",
    "- matplotlib\n",
    "- opencv\n",
    "\n",
    "For running this notebook in RHODS you will need to import a custom notebook that contains these dependencies, for instance:  \n",
    "`quay.io/mmurakam/face-recognition-notebook:face-recognition-notebook-v1.0.2`\n",
    "\n",
    "### Model\n",
    "\n",
    "You will need to access a running inference server that serves the target model. Follow these steps to deploy the model:\n",
    "1. Download the [Ultraface model ONNX file](https://github.com/mamurak/onnx-models/blob/main/vision/body_analysis/ultraface/models/version-RFB-640.onnx).\n",
    "2. Upload the model to an S3 bucket that RHODS can access. Any object storage that implements the S3 interface can be used such as AWS S3, Ceph S3, Minio.\n",
    "3. If not already present, create a Data Science Project in RHODS and configure a model server.\n",
    "4. Select `Deploy model`. Enter a name, select framework `onnx` and choose or create a data connection that contains the required S3 credentials and settings for accessing your model bucket. Click `Deploy`.\n",
    "5. Wait until the model has been deployed (`Deployed models` -> `Status` should be green). Note the `Inference endpoint` URL and the `Token secret` if you have selected token authentication (-> `Tokens`). You will need to paste these values into a cell further down this notebook.\n",
    "\n",
    "You can now run the following cells.\n",
    "\n",
    "## Import dependencies\n",
    "\n",
    "The code that executes the image preprocessing and rendering as well as communication with the inference service is included in our custom `image_utils` and `face_detection` modules, respectively. Check these modules out for the implementation details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427da5de-4555-4014-85ce-8db1f57f8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_detection import detect_faces\n",
    "from image_utils import load_and_preprocess, draw_image_and_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e087c9a-ae5b-4414-a9e4-f956d8246090",
   "metadata": {},
   "source": [
    "Copy and paste the `Inference endpoint` URL of your deployed model into the `prediction_url` definition. If you have configured token authentication in the model server, copy and paste the corresponding `Token secret` into the `token` definition below.\n",
    "\n",
    "The `image_path` points to an image in your local filesystem. You can test the inference server with the provided images in the `sample-images` folder or your own images that you upload to the local filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b8e81-cdd1-4116-9458-ee3e2c6e7b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_url = '' # enter your Inference endpoint URL here\n",
    "token = '' # enter your Token secret here, if available\n",
    "image_path = 'sample-images/1.jpg'\n",
    "\n",
    "original_image, preprocessed_image = load_and_preprocess(image_path)\n",
    "faces = detect_faces(preprocessed_image, prediction_url, token)\n",
    "draw_image_and_faces(original_image, *faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b6ea80-ffad-4a5f-9c06-9db14b425d89",
   "metadata": {},
   "source": [
    "### Load test the model service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e9a02-961c-436e-ae13-2a900fff10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    detect_faces(preprocessed_image, prediction_url, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d89aa0-7049-4206-8165-0bc37f0e5695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
