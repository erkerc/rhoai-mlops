{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUela Anomaly ML Model\n",
    "\n",
    "Goal: Build a machine lerning model that detects anomalies in sensor vibration data\n",
    "\n",
    "![anomalies](https://raw.githubusercontent.com/sa-mw-dach/manuela/master/docs/images/manuela-anomalies.png)\n",
    "\n",
    "Steps:\n",
    "- Wrangling sensor data \n",
    "- Save the training data\n",
    "- Prepare the data for modeling, training and testing\n",
    "- Train and validate models\n",
    "- Select and save the best model\n",
    "- Prototype class for Seldon model serving\n",
    "\n",
    "*Note: There are many ways to address the problem. ARIMA. baslining or forecasting with an LSTM neural network would be interesting. In this notebook we picked a rather simple approach, because the focus is on real-time alerts.*\n",
    "\n",
    "\n",
    "\n",
    "## Wrangling sensor data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('raw-data.csv')\n",
    "df['time'] = pd.to_datetime(df['ts'],unit='ms')\n",
    "df.set_index('time', inplace=True)\n",
    "df.drop(columns=['ts'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data over time\n",
    "Vibration pump 1: Data shows a few anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[df['id'] == 'pump-1']\n",
    "df1 = df1.drop(columns=['id', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vibration pump 2: Data shows a few anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[df['id'] == 'pump-2']\n",
    "df1 = df1.drop(columns=['id', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[df['id'] == 'pump-1']\n",
    "df1 = df1.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled data over time\n",
    "- Vibration pump 1. \n",
    "- Label = 1 -> Anomanly\n",
    "- The (manually) labeled data makes few more anomalies visibile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[df['id'] == 'pump-1']\n",
    "df1 = df1.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vibration pump 2: \n",
    "- Label = 1 -> Anomanly\n",
    "- The (manually) labeled data makes few more anomalies visibile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[df['id'] == 'pump-2']\n",
    "df2 = df2.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "Goal: Convert time series data into small episodes that can be uses for supervised learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Few helper functions\n",
    "#\n",
    "\n",
    "# Get list with column names: F1, F2, Fn, L\n",
    "def get_columns(n):\n",
    "    f = []\n",
    "    for x in range(1, n+1):\n",
    "        f.append(\"F\"+str(x))\n",
    "    f.append(\"L\")\n",
    "    return f\n",
    "\n",
    "\n",
    "# Create empty data frame\n",
    "def create_empty_df(n):\n",
    "    d = ([0.]*n)\n",
    "    d.append(0)\n",
    "    dfx = pd.DataFrame([d], columns=get_columns(n))\n",
    "    dfx.drop(dfx.index[0], inplace=True)\n",
    "    return dfx\n",
    "\n",
    "\n",
    "# Create data frame with one row\n",
    "def create_df(vals: list, label: int = 0):\n",
    "    if not isinstance(vals, list):\n",
    "        raise TypeError\n",
    "    dfx = pd.DataFrame([vals+[label]], columns=get_columns(len(vals)))\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataframe: Rows represent the last x (length) value and the label.\n",
    "\n",
    "```\n",
    "--+-----+-----\n",
    "tz value label\n",
    "--+-----+-----\n",
    "..  ...    0\n",
    "04  6.2    0\n",
    "05  7.2    0\n",
    "06  3.1    0\n",
    "07 12.4    1\n",
    "..  ...\n",
    "--+-----+-----\n",
    "```\n",
    "\n",
    "Convert to episodes with lenght = 3\n",
    "\n",
    "```\n",
    "---+----+----+---\n",
    "F1   F2   F3   L\n",
    "---+----+----+---\n",
    "..\n",
    "6.2  7.2  3.1  0\n",
    "7.2  3.1 12.4  1\n",
    "..\n",
    "---+----+----+---\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 5  # Episode length\n",
    "\n",
    "df_epis = create_empty_df(length)\n",
    "\n",
    "for id in df.id.unique():\n",
    "    print(\"Convert data for: \", id)\n",
    "\n",
    "    df2 = df.loc[df['id'] == id]\n",
    "\n",
    "    epi = []\n",
    "    for index, row in df2.iterrows():\n",
    "        # print('%6.2f, %d' % (row['value'], row['label']))\n",
    "        epi.append(row['value'])\n",
    "        if len(epi) == length:\n",
    "            df_row = create_df(epi, row['label'])\n",
    "            df_epis = df_epis.append(df_row, ignore_index=True)\n",
    "            del(epi[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_epis.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epis.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of episodes\n",
    "n_episodes = df_epis.shape[0]\n",
    "\n",
    "# Calculate number of features\n",
    "n_features = df_epis.shape[1] - 1\n",
    "\n",
    "# Calculate passing students\n",
    "n_anomaly = df_epis[df_epis['L'] == 1].shape[0]\n",
    "\n",
    "# TODO: Calculate failing students\n",
    "n_normal = df_epis[df_epis['L'] == 0].shape[0]\n",
    "\n",
    "# TODO: Calculate graduation rate\n",
    "anomaly_rate = n_anomaly / float(n_episodes) * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of episodes: {}\".format(n_episodes))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of episodes with anomaly: {}\".format(n_anomaly))\n",
    "print(\"Number of episodes witManipulatehout anomaly: {}\".format(n_normal))\n",
    "print(\"Anomaly rate in dataset: {:.2f}%\".format(anomaly_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's vary the anomalies to make the model more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 5  # Number of copies\n",
    "dfr = df_epis.copy()\n",
    "for i in range(1, factor):\n",
    "\n",
    "    f = 0.5 + ((i - 1) * 0.5 / (factor-1))  # vary the anomaly by a factor\n",
    "\n",
    "    dfi = df_epis.copy()\n",
    "    dfi['F5'] = np.where(dfi['L'] == 1, dfi['F5']*f, dfi['F5'])\n",
    "    dfr = dfr.append(dfi)\n",
    "\n",
    "df_epis = dfr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of episodes\n",
    "n_episodes = df_epis.shape[0]\n",
    "\n",
    "# Calculate number of features\n",
    "n_features = df_epis.shape[1] - 1\n",
    "\n",
    "# Calculate passing students\n",
    "n_anomaly = df_epis[df_epis['L'] == 1].shape[0]\n",
    "\n",
    "# TODO: Calculate failing students\n",
    "n_normal = df_epis[df_epis['L'] == 0].shape[0]\n",
    "\n",
    "# TODO: Calculate graduation rate\n",
    "anomaly_rate = n_anomaly / float(n_episodes) *100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of episodes: {}\".format(n_episodes))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of episodes with anomaly: {}\".format(n_anomaly))\n",
    "print(\"Number of episodes without anomaly: {}\".format(n_normal))\n",
    "print(\"Anomaly rate in dataset: {:.2f}%\".format(anomaly_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Training data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epis.to_csv(\n",
    "    'sensor-training-data.csv', index=False, header=True, float_format='%.2f'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
